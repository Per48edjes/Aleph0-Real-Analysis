\section{Key Theorems about Sequences}

\begin{problem}
  \label{prob:limit-laws}
  Prove the limit laws for sequences. That is, prove that if
  $(a_{n})_{n=1}^{\infty}$ and $(b_{n})_{n=1}^{\infty}$ are convergent, then:

    \begin{enumerate}[label=(\alph*)]
      \item $\lim\limits_{n \to \infty} {(a_{n})} + \lim\limits_{n \to \infty} {(b_{n})} = \lim\limits_{n \to \infty} {(a_{n} + b_{n})}$
        \label{prob:sum-limit-law}

        \begin{callout}
          This proof was \href{https://www.youtube.com/watch?v=Q7MzeAaL7bU&t=610s}{provided}.
        \end{callout}


      \item $\lim\limits_{n \to \infty} {(a_{n})} - \lim\limits_{n \to \infty} {(b_{n})} = \lim\limits_{n \to \infty} {(a_{n} - b_{n})}$
        \label{prob:subtraction-limit-law}

        \begin{proof}
          First, we will prove a useful lemma.

          \begin{lemma}[Scalar Multiplication of Limits]
            \label{lem:constant-multiplication-limit-law}
            If $\lim\limits_{n \to \infty} x_{n} = L$ (with $L \in \R$), then 
            \[
              \lim\limits_{n \to \infty} c(x_{n}) = c \cdot \lim\limits_{n \to \infty} (x_{n}) = c L
            \]
            where $c \in \R$ is a constant.
          \end{lemma}

          \begin{subproof}[Proof of \lemref{lem:constant-multiplication-limit-law}]
            Let $\eps > 0$ be given. Then, by convergence of $(x_{n})$ to $L$, there exists
            some $N \in \N$ such that $\abs{x_{n} - L} < \frac{\eps}{\abs{c}}$ for all $n > N$.
            Thus, 
            \begin{align*}
              \abs{x_{n} - L} < \frac{\eps}{\abs{c}} \iff & \abs{c}\abs{x_{n} - L} \\
                                                          &= \abs{c(x_{n} - L)} \\
                                                          &= \abs{cx_{n} - cL} < \eps,
            \end{align*}
            which shows that there exists an $N$ satisfying the definition of convergence (i.e., $(x_{n}) \to cL$) for our arbitrarily chosen $\eps$.
          \end{subproof}

          Combining the result of \ref{prob:sum-limit-law} and
          \lemref{lem:constant-multiplication-limit-law} (viz., letting $c = -1$) completes the proof.
        \end{proof}

      \item $\lim\limits_{n \to \infty} {(a_{n})} \cdot \lim\limits_{n \to \infty} {(b_{n})} = \lim\limits_{n \to \infty} {(a_{n}b_{n})}$ 
        \label{prob:product-limit-law}

        \begin{callout}
          This proof was \href{https://youtu.be/Q7MzeAaL7bU?si=uc3L6lvpQXdKwMGI&t=691}{provided}.
        \end{callout}

      \item $\lim\limits_{n \to \infty} {(a_{n})} / \lim\limits_{n \to \infty} {(b_{n})} = \lim\limits_{n \to \infty} {(a_{n} / b_{n})}$, provided that $\lim\limits_{n \to \infty} {b_{n}} \neq 0$
        and $b_{n} \neq 0$ for all $n$.
        \label{prob:division-limit-law}

        \begin{proof}
          First, we will prove a useful lemma.

          \begin{lemma}
            \label{lem:reciprocals-limit-law}
            If $x_{n} \neq 0$ for all $n$ and $\lim\limits_{n \to \infty} (x_{n}) = L$ (with $L \neq 0$), then
            \[
              \lim\limits_{n \to \infty} \dfrac{1}{(x_{n})} = \dfrac{1}{\lim\limits_{n \to \infty} (x_{n})} = \dfrac{1}{L}.
            \]
          \end{lemma}

          \begin{subproof}[Proof of \lemref{lem:reciprocals-limit-law}]
            First, we establish that $\abs{\dfrac{1}{(x_{n})}}$ is bounded for
            sufficiently large $n$. Since convergent\footnotemark{} sequences are
            bounded, we have $M' \leq \abs{x_{n}} \leq M$ for sufficiently large $n$
            (where $M', M > 0$), hence, 
            \footnotetext{Note that $\abs{x_{n}}$ converges from the result of
            \probref{prob:abs-value-of-convergent-sequence}.}
            \[
              \dfrac{1}{M'} \geq \abs{\dfrac{1}{x_{n}}} \geq \dfrac{1}{M}.
            \]
            Next, let $\eps > 0$ be arbitrary. We want to show that there exists
            an $N \in \N$ such that
            \begin{align*}
              n > N \implies \abs{\frac{1}{x_{n}} - \frac{1}{L}} < \eps.
            \end{align*}
            Let $N_{1} \in \N$ be the sufficiently large lower bound for $n$ that guarantees that
            $\dfrac{1}{M'} > \abs{\dfrac{1}{x_{n}}}$. By convergence of
            $(x_{n})$, we know that there exists an $N_{2} \in \N$ such that
            \[
              n > N_{2} \implies \abs{x_{n} - L} < \abs{L} (M') \eps.
            \]
            Set $N = \max(N_{1}, N_{2})$, demonstrating that for all $n > N$, we have
            \begin{align*}
              \abs{\dfrac{1}{x_{n}} - \dfrac{1}{L}} &= \abs{\dfrac{L - x_{n}}{x_{n}L}} \\
                                                    &= \abs{\dfrac{1}{L}} \abs{\dfrac{x_{n} - L}{x_{n}}} \\
                                                    &= \abs{\dfrac{1}{L}} \abs{\dfrac{1}{x_{n}}} \abs{x_{n} - L} \\
                                                    &\leq \abs{\dfrac{1}{L}} \left( \dfrac{1}{M'} \right) \abs{x_{n} - L} \\
                                                    &< \eps.
            \end{align*}
          \end{subproof}

          Combining the result of \ref{prob:product-limit-law} and
          \lemref{lem:reciprocals-limit-law} completes the proof.
        \end{proof}

    \end{enumerate}
\end{problem}

\begin{problem}
  Argue that the sequence $(1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, \ldots)$ 
  does not converge to zero. For what values of $\eps > 0$ does there exist a
  response $N$? For which values of $\eps < 0$ is there no
  suitable response? 

  \vspace{\baselineskip}

    We see that the definition of convergence (to suggest that the limit of the
    given sequence equals $0$) is satisfied when $\eps > 1$. However, no $N$
    exists such that, for all $n > N$, $\abs{a_{n}} < \eps$ whenever $0 < \eps \leq 1$. 
    (Alternatively, this sequence does not converge because there exists at least
    two different accumulation points: $1$ and $0$.)
\end{problem}

\begin{problem}
  Informally speaking, the sequence $(\sqrt{n})_{n=1}^{\infty}$ ``converges to infinity.''

  \begin{enumerate}[label=(\alph*)]
      \item Create a rigorous definition for the mathematical statement $\lim\limits_{n \to \infty} x_{n} = \infty$. Use this
        definition to prove $\lim_{n \to \infty} (\sqrt{n}) = \infty$.

        \begin{definition}[Convergence to $\infty$]
          \label{def:convergence-to-infty}
          The sequence $(x_{n})_{n=1}^{\infty}$ converges to $\infty$ if and only if
          for all $M > 0$, there exists $N \in \N$ such that $x_{n} > M$ 
          for all $n > N$.
        \end{definition}

        \begin{proof}
          Note that $(\sqrt{n})_{n=1}^{\infty}$ is strictly increasing with no upper bound. 
          Hence, for any $M > 0$, we can always find $N \in \N$ such that $x_{n} > M$ for all $n > N$. 
          Therefore, by \ref{def:convergence-to-infty}, the sequence $(\sqrt{n})_{n=1}^{\infty}$ 
          converges to infinity.
        \end{proof}

      \item What does \defref{def:convergence-to-infty} say about a particular sequence
        $(1, 0, 2, 0, 3, 0, 4, 0, 5, 0, \ldots)$?

        The subsequence $(0, 0, 0, 0, \ldots)$ is constantly $0$, which means
        the sequence cannot satisfy \defref{def:convergence-to-infty}. So,
        the sequence $(1, 0, 2, 0, 3, 0, 4, 0, 5, 0, \ldots)$ does not converge 
        to infinity. (We can, however, say that this sequence diverges.)

  \end{enumerate}
\end{problem}

\begin{problem}
  Create a rigorous definition for the mathematical statement 
  $\lim\limits_{n \to \infty} x_{n} = -\infty$. Give an example of a 
  sequence that satisfies this definition. 

    \begin{definition}[Convergence to $-\infty$]
      \label{def:convergence-to-neg-infty}
      The sequence $(x_{n})_{n=1}^{\infty}$ converges to $-\infty$ if and only if
      for all $M < 0$, there exists $N \in \N$ such that $x_{n} < M$ 
      for all $n > N$.
    \end{definition}

    An example of a sequence that satisfies \defref{def:convergence-to-neg-infty} is
    $(-e^{n})_{n=1}^{\infty}$.
\end{problem}

\begin{problem}
  Construct a sequence $(a_{n})$ such that $a_{n} > 0$ for all $n \in \N$,
  $\lim\limits_{n \to \infty} (a_{n}) = 0$, but
  $\lim\limits_{n \to \infty} \dfrac{1}{a_{n}} = \infty$.

  \vspace{\baselineskip}

    Consider $(a_{n}) = \left( \frac{1}{n} \right)_{n=1}^{\infty}$. It is clear that
    $\lim\limits_{n \to \infty} (a_{n}) = 0$ and that $(1, 2, 3, \ldots)$ ``converges to infinity''.

\end{problem}

\begin{problem}
  Prove or disprove: if $\lim\limits_{n \to \infty} (a_{n}) = 0$ and $(b_{n})$ is
  a bounded sequence, then $\lim\limits_{n \to \infty} (a_{n}b_{n}) = 0$.

  \begin{proof} 
    Note that $\abs{b_{n}}$ is bounded above by some $M > 0$ for all sufficiently large $n$.
    Let $N_{1} \in \N$ be such that $\abs{b_{n}} < M$ for all $n > N_{1}$. Then, by convergence
    of $(a_{n})$, there exists an $N_{2} \in \N$ such that 
    \[
      \abs{a_{n}} < \frac{\eps}{M}
    \]
    for all $n > N_{2}$. So, setting $N = \max{(N_{1}, N_{2})}$, we have
    \begin{align*}
      n > N \implies \abs{a_{n}b_{n}} &= \abs{a_{n}} \cdot \abs{b_{n}} \\
                                      &< \frac{\eps}{M} \cdot M \\
                                      &= \eps.
    \end{align*}
  \end{proof}

\end{problem}

\begin{problem}
  Let $(a_{n})$ be a sequence such that $a_{n} \geq 0$ for all $n \in \N$. 
  Prove that if $\sum\limits_{n=1}^{\infty} a_{n}$ converges, then
  $\lim\limits_{n \to \infty} a_{n} = 0$. Give an example to show that the 
  converse is false.

  \begin{proof} 
    Define the sequence $(s_{n}) = \sum\limits_{k=1}^{n} a_{k}$, which is the sequence of partial sums of $(a_{n})$.
    We can also define $s_{0} = 0$. From the hypothesis, we know $s_{n} \to L$ for some $L \in \R$ as $n \to \infty$.
    Then, the result of \probref{prob:limit-of-shifted-sequence-equal} and \probref{prob:limit-laws}\ref{prob:subtraction-limit-law}
    gives us
    \[
      L - L = \lim\limits_{n \to \infty} (s_{n} - s_{n - 1}) = \lim\limits_{n \to \infty} a_{n} = 0.
    \]
  \end{proof}

  Consider $(a_{n}) = \left( \frac{1}{n} \right)_{n=1}^{\infty}$ as a counterexample to the converse
  of the problem statement. This sequence converges to $0$, but the series diverges.


\end{problem}
